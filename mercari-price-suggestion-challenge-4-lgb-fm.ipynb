{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import time\nstart_time = time.time()\n\nSUBMIT_MODE = True\n\n\nimport pandas as pd\nimport numpy as np\nimport time\nimport gc\nimport string\nimport re\n\nfrom nltk.corpus import stopwords\n\nfrom scipy.sparse import csr_matrix, hstack\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_selection.univariate_selection import SelectKBest, f_regression\nfrom sklearn.preprocessing import LabelBinarizer\n\nimport wordbatch\nfrom wordbatch.batcher import Batcher\nfrom wordbatch.extractors import WordBag\nfrom wordbatch.models import FM_FTRL\nfrom wordbatch.pipelines import WordBatch\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import Ridge\nfrom sklearn.naive_bayes import MultinomialNB\nimport lightgbm as lgb\n\n\ndef rmse(predicted, actual):\n    return np.sqrt(((predicted - actual) ** 2).mean())\n\n\ndef split_cat(text):\n    try:\n        return text.split(\"/\")\n    except:\n        return (\"No Label\", \"No Label\", \"No Label\")\n\n\nclass TargetEncoder:\n    # Adapted from https://www.kaggle.com/ogrellier/python-target-encoding-for-categorical-features\n    def __repr__(self):\n        return 'TargetEncoder'\n\n    def __init__(self, cols, smoothing=1, min_samples_leaf=1, noise_level=0, keep_original=False):\n        self.cols = cols\n        self.smoothing = smoothing\n        self.min_samples_leaf = min_samples_leaf\n        self.noise_level = noise_level\n        self.keep_original = keep_original\n\n    @staticmethod\n    def add_noise(series, noise_level):\n        return series * (1 + noise_level * np.random.randn(len(series)))\n\n    def encode(self, train, test, target):\n        for col in self.cols:\n            if self.keep_original:\n                train[col + '_te'], test[col + '_te'] = self.encode_column(train[col], test[col], target)\n            else:\n                train[col], test[col] = self.encode_column(train[col], test[col], target)\n        return train, test\n\n    def encode_column(self, trn_series, tst_series, target):\n        temp = pd.concat([trn_series, target], axis=1)\n        # Compute target mean\n        averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n        # Compute smoothing\n        smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - self.min_samples_leaf) / self.smoothing))\n        # Apply average function to all target data\n        prior = target.mean()\n        # The bigger the count the less full_avg is taken into account\n        averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n        averages.drop(['mean', 'count'], axis=1, inplace=True)\n        # Apply averages to trn and tst series\n        ft_trn_series = pd.merge(\n            trn_series.to_frame(trn_series.name),\n            averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n            on=trn_series.name,\n            how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n        # pd.merge does not keep the index so restore it\n        ft_trn_series.index = trn_series.index\n        ft_tst_series = pd.merge(\n            tst_series.to_frame(tst_series.name),\n            averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n            on=tst_series.name,\n            how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n        # pd.merge does not keep the index so restore it\n        ft_tst_series.index = tst_series.index\n        return self.add_noise(ft_trn_series, self.noise_level), self.add_noise(ft_tst_series, self.noise_level)   \n\n\ndef to_number(x):\n    try:\n        if not x.isdigit():\n            return 0\n        x = int(x)\n        if x > 100:\n            return 100\n        else:\n            return x\n    except:\n        return 0\n\ndef sum_numbers(desc):\n    if not isinstance(desc, str):\n        return 0\n    try:\n        return sum([to_number(s) for s in desc.split()])\n    except:\n        return 0\n\n\n# Define helpers for text normalization\nstopwords = {x: 1 for x in stopwords.words('english')}\nnon_alphanums = re.compile(u'[^A-Za-z0-9]+')\nnon_alphanumpunct = re.compile(u'[^A-Za-z0-9\\.?!,; \\(\\)\\[\\]\\'\\\"\\$]+')\nRE_PUNCTUATION = '|'.join([re.escape(x) for x in string.punctuation])\n\ndef normalize_text(text):\n    return u\" \".join(\n        [x for x in [y for y in non_alphanums.sub(' ', text).lower().strip().split(\" \")] \\\n         if len(x) > 1 and x not in stopwords])\n\ndef clean_name(x):\n    if len(x):\n        x = non_alphanums.sub(' ', x).split()\n        if len(x):\n            return x[0].lower()\n    return ''\n\n    \nprint('[{}] Finished defining stuff'.format(time.time() - start_time))\n\n\ntrain = pd.read_table('../input/mercari-price/train.tsv', engine='c', \n                      dtype={'item_condition_id': 'category',\n                             'shipping': 'category',\n                            }, \n                     converters={'category_name': split_cat})\ntest = pd.read_table('../input/mercari-price/test.tsv', engine='c', \n                      dtype={'item_condition_id': 'category',\n                             'shipping': 'category',\n                            },\n                    converters={'category_name': split_cat})\nprint('[{}] Finished load data'.format(time.time() - start_time))\n\ntrain['is_train'] = 1\ntest['is_train'] = 0\nprint('[{}] Compiled train / test'.format(time.time() - start_time))\nprint('Train shape: ', train.shape)\nprint('Test shape: ', test.shape)\n\ntrain = train[train.price != 0].reset_index(drop=True)\nprint('[{}] Removed nonzero price'.format(time.time() - start_time))\nprint('Train shape: ', train.shape)\nprint('Test shape: ', test.shape)\n\ny = np.log1p(train['price'])\nnrow_train = train.shape[0]\n\nmerge = pd.concat([train, test])\nsubmission = test[['test_id']]\nprint('[{}] Compiled merge'.format(time.time() - start_time))\nprint('Merge shape: ', merge.shape)\n\n\ndel train\ndel test\nmerge.drop(['train_id', 'test_id', 'price'], axis=1, inplace=True)\ngc.collect()\nprint('[{}] Garbage collection'.format(time.time() - start_time))\n\n\nmerge['gencat_name'] = merge['category_name'].str.get(0).replace('', 'missing').astype('category')\nmerge['subcat1_name'] = merge['category_name'].str.get(1).fillna('missing').astype('category')\nmerge['subcat2_name'] = merge['category_name'].str.get(2).fillna('missing').astype('category')\nmerge.drop('category_name', axis=1, inplace=True)\nprint('[{}] Split categories completed.'.format(time.time() - start_time))\n\nmerge['item_condition_id'] = merge['item_condition_id'].cat.add_categories(['missing']).fillna('missing')\nmerge['shipping'] = merge['shipping'].cat.add_categories(['missing']).fillna('missing')\nmerge['item_description'].fillna('missing', inplace=True)\nmerge['brand_name'] = merge['brand_name'].fillna('missing').astype('category')\nprint('[{}] Handle missing completed.'.format(time.time() - start_time))\n\n\nmerge['name_first'] = merge['name'].apply(clean_name)\nprint('[{}] FE 1/37'.format(time.time() - start_time))\nmerge['name_first_count'] = merge.groupby('name_first')['name_first'].transform('count')\nprint('[{}] FE 2/37'.format(time.time() - start_time))\nmerge['gencat_name_count'] = merge.groupby('gencat_name')['gencat_name'].transform('count')\nprint('[{}] FE 3/37'.format(time.time() - start_time))\nmerge['subcat1_name_count'] = merge.groupby('subcat1_name')['subcat1_name'].transform('count')\nprint('[{}] FE 4/37'.format(time.time() - start_time))\nmerge['subcat2_name_count'] = merge.groupby('subcat2_name')['subcat2_name'].transform('count')\nprint('[{}] FE 5/37'.format(time.time() - start_time))\nmerge['brand_name_count'] = merge.groupby('brand_name')['brand_name'].transform('count')\nprint('[{}] FE 6/37'.format(time.time() - start_time))\nmerge['NameLower'] = merge.name.str.count('[a-z]')\nprint('[{}] FE 7/37'.format(time.time() - start_time))\nmerge['DescriptionLower'] = merge.item_description.str.count('[a-z]')\nprint('[{}] FE 8/37'.format(time.time() - start_time))\nmerge['NameUpper'] = merge.name.str.count('[A-Z]')\nprint('[{}] FE 9/37'.format(time.time() - start_time))\nmerge['DescriptionUpper'] = merge.item_description.str.count('[A-Z]')\nprint('[{}] FE 10/37'.format(time.time() - start_time))\nmerge['name_len'] = merge['name'].apply(lambda x: len(x))\nprint('[{}] FE 11/37'.format(time.time() - start_time))\nmerge['des_len'] = merge['item_description'].apply(lambda x: len(x))\nprint('[{}] FE 12/37'.format(time.time() - start_time))\nmerge['name_desc_len_ratio'] = merge['name_len']/merge['des_len']\nprint('[{}] FE 13/37'.format(time.time() - start_time))\nmerge['desc_word_count'] = merge['item_description'].apply(lambda x: len(x.split()))\nprint('[{}] FE 14/37'.format(time.time() - start_time))\nmerge['mean_des'] = merge['item_description'].apply(lambda x: 0 if len(x) == 0 else float(len(x.split())) / len(x)) * 10\nprint('[{}] FE 15/37'.format(time.time() - start_time))\nmerge['name_word_count'] = merge['name'].apply(lambda x: len(x.split()))\nprint('[{}] FE 16/37'.format(time.time() - start_time))\nmerge['mean_name'] = merge['name'].apply(lambda x: 0 if len(x) == 0 else float(len(x.split())) / len(x))  * 10\nprint('[{}] FE 17/37'.format(time.time() - start_time))\nmerge['desc_letters_per_word'] = merge['des_len'] / merge['desc_word_count']\nprint('[{}] FE 18/37'.format(time.time() - start_time))\nmerge['name_letters_per_word'] = merge['name_len'] / merge['name_word_count']\nprint('[{}] FE 19/37'.format(time.time() - start_time))\nmerge['NameLowerRatio'] = merge['NameLower'] / merge['name_len']\nprint('[{}] FE 20/37'.format(time.time() - start_time))\nmerge['DescriptionLowerRatio'] = merge['DescriptionLower'] / merge['des_len']\nprint('[{}] FE 21/37'.format(time.time() - start_time))\nmerge['NameUpperRatio'] = merge['NameUpper'] / merge['name_len']\nprint('[{}] FE 22/37'.format(time.time() - start_time))\nmerge['DescriptionUpperRatio'] = merge['DescriptionUpper'] / merge['des_len']\nprint('[{}] FE 23/37'.format(time.time() - start_time))\nmerge['NamePunctCount'] = merge.name.str.count(RE_PUNCTUATION)\nprint('[{}] FE 24/37'.format(time.time() - start_time))\nmerge['DescriptionPunctCount'] = merge.item_description.str.count(RE_PUNCTUATION)\nprint('[{}] FE 25/37'.format(time.time() - start_time))\nmerge['NamePunctCountRatio'] = merge['NamePunctCount'] / merge['name_word_count']\nprint('[{}] FE 26/37'.format(time.time() - start_time))\nmerge['DescriptionPunctCountRatio'] = merge['DescriptionPunctCount'] / merge['desc_word_count']\nprint('[{}] FE 27/37'.format(time.time() - start_time))\nmerge['NameDigitCount'] = merge.name.str.count('[0-9]')\nprint('[{}] FE 28/37'.format(time.time() - start_time))\nmerge['DescriptionDigitCount'] = merge.item_description.str.count('[0-9]')\nprint('[{}] FE 29/37'.format(time.time() - start_time))\nmerge['NameDigitCountRatio'] = merge['NameDigitCount'] / merge['name_word_count']\nprint('[{}] FE 30/37'.format(time.time() - start_time))\nmerge['DescriptionDigitCountRatio'] = merge['DescriptionDigitCount']/merge['desc_word_count']\nprint('[{}] FE 31/37'.format(time.time() - start_time))\nmerge['stopword_ratio_desc'] = merge['item_description'].apply(lambda x: len([w for w in x.split() if w in stopwords])) / merge['desc_word_count']\nprint('[{}] FE 32/37'.format(time.time() - start_time))\nmerge['num_sum'] = merge['item_description'].apply(sum_numbers) \nprint('[{}] FE 33/37'.format(time.time() - start_time))\nmerge['weird_characters_desc'] = merge['item_description'].str.count(non_alphanumpunct)\nprint('[{}] FE 34/37'.format(time.time() - start_time))\nmerge['weird_characters_name'] = merge['name'].str.count(non_alphanumpunct)\nprint('[{}] FE 35/37'.format(time.time() - start_time))\nmerge['prices_count'] = merge['item_description'].str.count('[rm]')\nprint('[{}] FE 36/37'.format(time.time() - start_time))\nmerge['price_in_name'] = merge['item_description'].str.contains('[rm]', regex=False).astype('int')\nprint('[{}] FE 37/37'.format(time.time() - start_time))\n\ncols = set(merge.columns.values)\nbasic_cols = {'name', 'item_condition_id', 'brand_name',\n  'shipping', 'item_description', 'gencat_name',\n  'subcat1_name', 'subcat2_name', 'name_first', 'is_train'}\n\ncols_to_normalize = cols - basic_cols - {'price_in_name'}\nother_cols = basic_cols | {'price_in_name'}\n\nmerge_to_normalize = merge[list(cols_to_normalize)]\nmerge_to_normalize = (merge_to_normalize - merge_to_normalize.mean()) / (merge_to_normalize.max() - merge_to_normalize.min())\nprint('[{}] FE Normalized'.format(time.time() - start_time))\n\nmerge = merge[list(other_cols)]\nmerge = pd.concat([merge, merge_to_normalize],axis=1)\nprint('[{}] FE Merged'.format(time.time() - start_time))\n\ndel(merge_to_normalize)\ngc.collect()\nprint('[{}] Garbage collection'.format(time.time() - start_time))\n\n\ndf_test = merge.loc[merge['is_train'] == 0]\ndf_train = merge.loc[merge['is_train'] == 1]\ndel merge\ngc.collect()\ndf_test = df_test.drop(['is_train'], axis=1)\ndf_train = df_train.drop(['is_train'], axis=1)\n\nif SUBMIT_MODE:\n    y_train = y\n    del y\n    gc.collect()\nelse:\n    df_train, df_test, y_train, y_test = train_test_split(df_train, y, test_size=0.2, random_state=144)\n\nprint('[{}] Splitting completed.'.format(time.time() - start_time))\n\nwb = WordBatch(normalize_text, extractor=WordBag(hash_ngrams=2,\n                                                 hash_ngrams_weights=[1.5,1.0],\n                                                 hash_size=2**29,\n                                                 norm=None, tf='binary',idf=None),batcher=Batcher(backend=\"multiprocessing\"))\nwb.dictionary_freeze = True\nX_name_train = wb.fit_transform(df_train['name'])\nX_name_test = wb.transform(df_test['name'])\ndel(wb)\nmask = np.where(X_name_train.getnnz(axis=0) > 3)[0]\nX_name_train = X_name_train[:, mask]\nX_name_test = X_name_test[:, mask]\nprint('[{}] Vectorize `name` completed.'.format(time.time() - start_time))\n\n\nwb = WordBatch(normalize_text, extractor=WordBag(hash_ngrams=2,hash_ngrams_weights=[1.0,1.0],\n                                                  hash_size=2**28,\n                                                  norm=12, tf=1.0,idf=None),batcher=Batcher(backend=\"multiprocessing\"))\nwb.dictionary_freeze = True\nX_description_train = wb.fit_transform(df_train['item_description'])\nX_description_test = wb.transform(df_test['item_description'])\ndel(wb)\nmask = np.where(X_description_train.getnnz(axis=0) > 3)[0]\nX_description_train = X_description_train[:, mask]\nX_description_test = X_description_test[:, mask]\nprint('[{}] Vectorize `item_description` completed.'.format(time.time() - start_time))\n\n\nX_train_1, X_train_2, y_train_1, y_train_2 = train_test_split(X_description_train, y_train,\n                                                              test_size = 0.5,\n                                                              shuffle = False)\nprint('[{}] Finished splitting'.format(time.time() - start_time))\n\n# Ridge adapted from https://www.kaggle.com/object/more-effective-ridge-script?scriptVersionId=1851819\nmodel = Ridge(solver=\"sag\", fit_intercept=True, random_state=205, alpha=3.3)\nmodel.fit(X_train_1, y_train_1)\nprint('[{}] Finished to train desc ridge (1)'.format(time.time() - start_time))\ndesc_ridge_preds1 = model.predict(X_train_2)\ndesc_ridge_preds1f = model.predict(X_description_test)\nprint('[{}] Finished to predict desc ridge (1)'.format(time.time() - start_time))\nmodel = Ridge(solver=\"sag\", fit_intercept=True, random_state=205, alpha=3.3)\nmodel.fit(X_train_2, y_train_2)\nprint('[{}] Finished to train desc ridge (2)'.format(time.time() - start_time))\ndesc_ridge_preds2 = model.predict(X_train_1)\ndesc_ridge_preds2f = model.predict(X_description_test)\nprint('[{}] Finished to predict desc ridge (2)'.format(time.time() - start_time))\ndesc_ridge_preds_oof = np.concatenate((desc_ridge_preds2, desc_ridge_preds1), axis=0)\ndesc_ridge_preds_test = (desc_ridge_preds1f + desc_ridge_preds2f) / 2.0\nprint('RMSLE OOF: {}'.format(rmse(desc_ridge_preds_oof, y_train)))\nif not SUBMIT_MODE:\n    print('RMSLE TEST: {}'.format(rmse(desc_ridge_preds_test, y_test)))\n\n\nX_train_1, X_train_2, y_train_1, y_train_2 = train_test_split(X_name_train, y_train,\n                                                              test_size = 0.5,\n                                                              shuffle = False)\nprint('[{}] Finished splitting'.format(time.time() - start_time))\n\n# Ridge adapted from https://www.kaggle.com/object/more-effective-ridge-script?scriptVersionId=1851819\nmodel = Ridge(solver=\"sag\", fit_intercept=True, random_state=205, alpha=3.3)\nmodel.fit(X_train_1, y_train_1)\nprint('[{}] Finished to train name ridge (1)'.format(time.time() - start_time))\nname_ridge_preds1 = model.predict(X_train_2)\nname_ridge_preds1f = model.predict(X_name_test)\nprint('[{}] Finished to predict name ridge (1)'.format(time.time() - start_time))\nmodel = Ridge(solver=\"sag\", fit_intercept=True, random_state=205, alpha=3.3)\nmodel.fit(X_train_2, y_train_2)\nprint('[{}] Finished to train name ridge (2)'.format(time.time() - start_time))\nname_ridge_preds2 = model.predict(X_train_1)\nname_ridge_preds2f = model.predict(X_name_test)\nprint('[{}] Finished to predict name ridge (2)'.format(time.time() - start_time))\nname_ridge_preds_oof = np.concatenate((name_ridge_preds2, name_ridge_preds1), axis=0)\nname_ridge_preds_test = (name_ridge_preds1f + name_ridge_preds2f) / 2.0\nprint('RMSLE OOF: {}'.format(rmse(name_ridge_preds_oof, y_train)))\nif not SUBMIT_MODE:\n    print('RMSLE TEST: {}'.format(rmse(name_ridge_preds_test, y_test)))\n\n\ndel X_train_1\ndel X_train_2\ndel y_train_1\ndel y_train_2\ndel name_ridge_preds1\ndel name_ridge_preds1f\ndel name_ridge_preds2\ndel name_ridge_preds2f\ndel desc_ridge_preds1\ndel desc_ridge_preds1f\ndel desc_ridge_preds2\ndel desc_ridge_preds2f\ngc.collect()\nprint('[{}] Finished garbage collection'.format(time.time() - start_time))\n\n\nlb = LabelBinarizer(sparse_output=True)\nX_brand_train = lb.fit_transform(df_train['brand_name'])\nX_brand_test = lb.transform(df_test['brand_name'])\nprint('[{}] Finished label binarize `brand_name`'.format(time.time() - start_time))\n\nX_cat_train = lb.fit_transform(df_train['gencat_name'])\nX_cat_test = lb.transform(df_test['gencat_name'])\nX_cat1_train = lb.fit_transform(df_train['subcat1_name'])\nX_cat1_test = lb.transform(df_test['subcat1_name'])\nX_cat2_train = lb.fit_transform(df_train['subcat2_name'])\nX_cat2_test = lb.transform(df_test['subcat2_name'])\nprint('[{}] Finished label binarize categories'.format(time.time() - start_time))\n\nX_dummies_train = csr_matrix(\n    pd.get_dummies(df_train[list(cols - (basic_cols - {'item_condition_id', 'shipping'}))],\n                   sparse=True).values)\nprint('[{}] Create dummies completed - train'.format(time.time() - start_time))\n\nX_dummies_test = csr_matrix(\n    pd.get_dummies(df_test[list(cols - (basic_cols - {'item_condition_id', 'shipping'}))],\n                   sparse=True).values)\nprint('[{}] Create dummies completed - test'.format(time.time() - start_time))\n\nsparse_merge_train = hstack((X_dummies_train, X_description_train, X_brand_train, X_cat_train,\n                             X_cat1_train, X_cat2_train, X_name_train)).tocsr()\ndel X_description_train, lb, X_name_train, X_dummies_train\ngc.collect()\nprint('[{}] Create sparse merge train completed'.format(time.time() - start_time))\n\nsparse_merge_test = hstack((X_dummies_test, X_description_test, X_brand_test, X_cat_test,\n                             X_cat1_test, X_cat2_test, X_name_test)).tocsr()\ndel X_description_test, X_name_test, X_dummies_test\ngc.collect()\nprint('[{}] Create sparse merge test completed'.format(time.time() - start_time))\n\n\nif SUBMIT_MODE:\n    iters = 3\nelse:\n    iters = 1\n    rounds = 3\n\nmodel = FM_FTRL(alpha=0.035, beta=0.001, L1=0.00001, L2=0.15, D=sparse_merge_train.shape[1],\n                alpha_fm=0.05, L2_fm=0.0, init_fm=0.01,\n                D_fm=100, e_noise=0, iters=iters, inv_link=\"identity\", threads=4)\n\nif SUBMIT_MODE:\n    model.fit(sparse_merge_train, y_train)\n    print('[{}] Train FM completed'.format(time.time() - start_time))\n    predsFM = model.predict(sparse_merge_test)\n    print('[{}] Predict FM completed'.format(time.time() - start_time))\nelse:\n    for i in range(rounds):\n        model.fit(sparse_merge_train, y_train)\n        predsFM = model.predict(sparse_merge_test)\n        print('[{}] Iteration {}/{} -- RMSLE: {}'.format(time.time() - start_time, i + 1, rounds, rmse(predsFM, y_test)))\n\ndel model\ngc.collect()\nif not SUBMIT_MODE:\n    print(\"FM_FTRL dev RMSLE:\", rmse(predsFM, y_test))\n\n\nfselect = SelectKBest(f_regression, k=48000)\ntrain_features = fselect.fit_transform(sparse_merge_train, y_train)\ntest_features = fselect.transform(sparse_merge_test)\nprint('[{}] Select best completed'.format(time.time() - start_time))\n\n\ndel sparse_merge_train\ndel sparse_merge_test\ngc.collect()\nprint('[{}] Garbage collection'.format(time.time() - start_time))\n\n\ntv = TfidfVectorizer(max_features=250000,\n                     ngram_range=(1, 3),\n                     stop_words=None)\nX_name_train = tv.fit_transform(df_train['name'])\nprint('[{}] Finished TFIDF vectorize `name` (1/2)'.format(time.time() - start_time))\nX_name_test = tv.transform(df_test['name'])\nprint('[{}] Finished TFIDF vectorize `name` (2/2)'.format(time.time() - start_time))\n\ntv = TfidfVectorizer(max_features=500000,\n                     ngram_range=(1, 3),\n                     stop_words=None)\nX_description_train = tv.fit_transform(df_train['item_description'])\nprint('[{}] Finished TFIDF vectorize `item_description` (1/2)'.format(time.time() - start_time))\nX_description_test = tv.transform(df_test['item_description'])\nprint('[{}] Finished TFIDF vectorize `item_description` (2/2)'.format(time.time() - start_time))\n\nX_dummies_train = csr_matrix(\n    pd.get_dummies(df_train[['item_condition_id', 'shipping']], sparse=True).values)\nX_dummies_test = csr_matrix(\n    pd.get_dummies(df_test[['item_condition_id', 'shipping']], sparse=True).values)\n\nsparse_merge_train = hstack((X_description_train, X_brand_train, X_cat_train,\n                             X_cat1_train, X_cat2_train, X_name_train)).tocsr()\ndel X_dummies_train, X_description_train, X_brand_train, X_cat_train\ndel X_cat1_train, X_cat2_train, X_name_train\ngc.collect()\nprint('[{}] Create sparse merge train completed'.format(time.time() - start_time))\n\nsparse_merge_test = hstack((X_description_test, X_brand_test, X_cat_test,\n                            X_cat1_test, X_cat2_test, X_name_test)).tocsr()\ndel X_dummies_test, X_description_test, X_brand_test, X_cat_test\ndel X_cat1_test, X_cat2_test, X_name_test\ngc.collect()\nprint('[{}] Create sparse merge test completed'.format(time.time() - start_time))\n\n\nX_train_1, X_train_2, y_train_1, y_train_2 = train_test_split(sparse_merge_train, y_train,\n                                                              test_size = 0.5,\n                                                              shuffle = False)\nprint('[{}] Finished splitting'.format(time.time() - start_time))\n\n\nmodel = Ridge(solver=\"sag\", fit_intercept=True, random_state=205, alpha=3.3)\nmodel.fit(X_train_1, y_train_1)\nprint('[{}] Finished to train ridge (1)'.format(time.time() - start_time))\nridge_preds1 = model.predict(X_train_2)\nridge_preds1f = model.predict(sparse_merge_test)\nprint('[{}] Finished to predict ridge (1)'.format(time.time() - start_time))\nmodel = Ridge(solver=\"sag\", fit_intercept=True, random_state=205, alpha=3.3)\nmodel.fit(X_train_2, y_train_2)\nprint('[{}] Finished to train ridge (2)'.format(time.time() - start_time))\nridge_preds2 = model.predict(X_train_1)\nridge_preds2f = model.predict(sparse_merge_test)\nprint('[{}] Finished to predict ridge (2)'.format(time.time() - start_time))\nridge_preds_oof = np.concatenate((ridge_preds2, ridge_preds1), axis=0)\nridge_preds_test = (ridge_preds1f + ridge_preds2f) / 2.0\nprint('RMSLE OOF: {}'.format(rmse(ridge_preds_oof, y_train)))\nif not SUBMIT_MODE:\n    print('RMSLE TEST: {}'.format(rmse(ridge_preds_test, y_test)))\n\n\nmodel = MultinomialNB(alpha=0.01)\nmodel.fit(X_train_1, y_train_1 >= 4)\nprint('[{}] Finished to train MNB (1)'.format(time.time() - start_time))\nmnb_preds1 = model.predict_proba(X_train_2)[:, 1]\nmnb_preds1f = model.predict_proba(sparse_merge_test)[:, 1]\nprint('[{}] Finished to predict MNB (1)'.format(time.time() - start_time))\nmodel = MultinomialNB(alpha=0.01)\nmodel.fit(X_train_2, y_train_2 >= 4)\nprint('[{}] Finished to train MNB (2)'.format(time.time() - start_time))\nmnb_preds2 = model.predict_proba(X_train_1)[:, 1]\nmnb_preds2f = model.predict_proba(sparse_merge_test)[:, 1]\nprint('[{}] Finished to predict MNB (2)'.format(time.time() - start_time))\nmnb_preds_oof = np.concatenate((mnb_preds2, mnb_preds1), axis=0)\nmnb_preds_test = (mnb_preds1f + mnb_preds2f) / 2.0\n\n\ndel ridge_preds1\ndel ridge_preds1f\ndel ridge_preds2\ndel ridge_preds2f\ndel mnb_preds1\ndel mnb_preds1f\ndel mnb_preds2\ndel mnb_preds2f\ndel X_train_1\ndel X_train_2\ndel y_train_1\ndel y_train_2\ndel sparse_merge_train\ndel sparse_merge_test\ndel model\ngc.collect()\nprint('[{}] Finished garbage collection'.format(time.time() - start_time))\n\n\ndf_train['ridge'] = ridge_preds_oof\ndf_train['name_ridge'] = name_ridge_preds_oof\ndf_train['desc_ridge'] = desc_ridge_preds_oof\ndf_train['mnb'] = mnb_preds_oof\ndf_test['ridge'] = ridge_preds_test\ndf_test['name_ridge'] = name_ridge_preds_test\ndf_test['desc_ridge'] = desc_ridge_preds_test\ndf_test['mnb'] = mnb_preds_test\nprint('[{}] Finished adding submodels'.format(time.time() - start_time))\n\n\nf_cats = ['brand_name', 'gencat_name', 'subcat1_name', 'subcat2_name', 'name_first']\ntarget_encode = TargetEncoder(min_samples_leaf=100, smoothing=10, noise_level=0.01,\n                              keep_original=True, cols=f_cats)\ndf_train, df_test = target_encode.encode(df_train, df_test, y_train)\nprint('[{}] Finished target encoding'.format(time.time() - start_time))\n\n\ndf_train.drop(f_cats, axis=1, inplace=True)\ndf_test.drop(f_cats, axis=1, inplace=True)\ndel mnb_preds_oof\ndel mnb_preds_test\ndel ridge_preds_oof\ndel ridge_preds_test\ngc.collect()\nprint('[{}] Finished garbage collection'.format(time.time() - start_time))\n\n\ncols = ['gencat_name_te', 'brand_name_te', 'subcat1_name_te', 'subcat2_name_te',\n        'name_first_te', 'mnb', 'desc_ridge', 'name_ridge', 'ridge']\ntrain_dummies = csr_matrix(df_train[cols].values)\nprint('[{}] Finished dummyizing model 1/5'.format(time.time() - start_time))\ntest_dummies = csr_matrix(df_test[cols].values)\nprint('[{}] Finished dummyizing model 2/5'.format(time.time() - start_time))\ndel df_train\ndel df_test\ngc.collect()\nprint('[{}] Finished dummyizing model 3/5'.format(time.time() - start_time))\ntrain_features = hstack((train_features, train_dummies)).tocsr()\nprint('[{}] Finished dummyizing model 4/5'.format(time.time() - start_time))\ntest_features = hstack((test_features, test_dummies)).tocsr()\nprint('[{}] Finished dummyizing model 5/5'.format(time.time() - start_time))\n\n\nd_train = lgb.Dataset(train_features, label=y_train)\ndel train_features; gc.collect()\nif SUBMIT_MODE:\n    watchlist = [d_train]\nelse:\n    d_valid = lgb.Dataset(test_features, label=y_test)\n    watchlist = [d_train, d_valid]\n\nparams = {\n    'learning_rate': 0.15,\n    'application': 'regression',\n    'max_depth': 13,\n    'num_leaves': 400,\n    'verbosity': -1,\n    'metric': 'RMSE',\n    'data_random_seed': 1,\n    'bagging_fraction': 0.8,\n    'feature_fraction': 0.6,\n    'nthread': 4,\n    'lambda_l1': 10,\n    'lambda_l2': 10\n}\nprint('[{}] Finished compiling LGB'.format(time.time() - start_time))\n\nmodelL = lgb.train(params,\n                  train_set=d_train,\n                  num_boost_round=1350,\n                  valid_sets=watchlist,\n                  verbose_eval=50)\n\npredsL = modelL.predict(test_features)\npredsL[predsL < 0] = 0\n\nif not SUBMIT_MODE:\n    print(\"LGB RMSLE:\", rmse(predsL, y_test))\n\ndel d_train\ndel modelL\nif not SUBMIT_MODE:\n    del d_valid\ngc.collect()\n\n\npreds_final = predsFM * 0.33 + predsL * 0.67\nif not SUBMIT_MODE:\n    print('Final RMSE: ', rmse(preds_final, y_test))\n\n\nif SUBMIT_MODE:\n    preds_final = np.expm1(preds_final)\n    submission['price'] = preds_final\n    submission.to_csv('lgb_and_fm_separate_train_test.csv', index=False)\n    print('[{}] Writing submission done'.format(time.time() - start_time))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-08T01:48:12.972323Z","iopub.execute_input":"2021-08-08T01:48:12.972941Z","iopub.status.idle":"2021-08-08T04:54:58.128841Z","shell.execute_reply.started":"2021-08-08T01:48:12.972829Z","shell.execute_reply":"2021-08-08T04:54:58.127522Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.feature_selection.univariate_selection module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n  warnings.warn(message, FutureWarning)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}},{"name":"stdout","text":"[2.966765880584717] Finished defining stuff\n[22.813430309295654] Finished load data\n[22.817615270614624] Compiled train / test\nTrain shape:  (1482535, 9)\nTest shape:  (693359, 8)\n[23.232276678085327] Removed nonzero price\nTrain shape:  (1481661, 9)\nTest shape:  (693359, 8)\n[23.733339071273804] Compiled merge\nMerge shape:  (2175020, 10)\n[24.95901656150818] Garbage collection\n[32.400395154953] Split categories completed.\n[33.34217023849487] Handle missing completed.\n[41.734612703323364] FE 1/37\n[42.39884090423584] FE 2/37\n[42.42762112617493] FE 3/37\n[42.457173109054565] FE 4/37\n[42.48893618583679] FE 5/37\n[42.51968812942505] FE 6/37\n[53.50232815742493] FE 7/37\n[99.95977711677551] FE 8/37\n[104.6839554309845] FE 9/37\n[118.70232319831848] FE 10/37\n[120.05986547470093] FE 11/37\n[121.59502100944519] FE 12/37\n[121.61173820495605] FE 13/37\n[126.87450551986694] FE 14/37\n[133.03544664382935] FE 15/37\n[135.14770674705505] FE 16/37\n[137.73091411590576] FE 17/37\n[137.7451798915863] FE 18/37\n[137.75855088233948] FE 19/37\n[137.77244925498962] FE 20/37\n[137.786705493927] FE 21/37\n[137.80095076560974] FE 22/37\n[138.10289669036865] FE 23/37\n[141.1567816734314] FE 24/37\n[151.6845452785492] FE 25/37\n[151.6960666179657] FE 26/37\n[151.70953845977783] FE 27/37\n[154.89204096794128] FE 28/37\n[164.19993543624878] FE 29/37\n[164.21124029159546] FE 30/37\n[164.22222709655762] FE 31/37\n[176.2539927959442] FE 32/37\n[192.8967478275299] FE 33/37\n[206.7468650341034] FE 34/37\n[210.9134078025818] FE 35/37\n[224.9479877948761] FE 36/37\n[225.9032907485962] FE 37/37\n[227.88316941261292] FE Normalized\n[228.7641327381134] FE Merged\n[228.93783330917358] Garbage collection\n[230.429790019989] Splitting completed.\n[407.53698539733887] Vectorize `name` completed.\n[683.1909456253052] Vectorize `item_description` completed.\n[683.3876008987427] Finished splitting\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:556: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n  '\"sag\" solver requires many iterations to fit '\n","output_type":"stream"},{"name":"stdout","text":"[852.7569661140442] Finished to train desc ridge (1)\n[853.0492038726807] Finished to predict desc ridge (1)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:556: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n  '\"sag\" solver requires many iterations to fit '\n","output_type":"stream"},{"name":"stdout","text":"[1039.0373888015747] Finished to train desc ridge (2)\n[1039.2888040542603] Finished to predict desc ridge (2)\nRMSLE OOF: 0.6096471163278652\n[1039.4257719516754] Finished splitting\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:556: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n  '\"sag\" solver requires many iterations to fit '\n","output_type":"stream"},{"name":"stdout","text":"[1056.8956956863403] Finished to train name ridge (1)\n[1056.940690279007] Finished to predict name ridge (1)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:556: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n  '\"sag\" solver requires many iterations to fit '\n","output_type":"stream"},{"name":"stdout","text":"[1074.3793568611145] Finished to train name ridge (2)\n[1074.4259994029999] Finished to predict name ridge (2)\nRMSLE OOF: 0.5126822169132915\n[1074.7019205093384] Finished garbage collection\n[1488.795284986496] Finished label binarize `brand_name`\n[1611.1177706718445] Finished label binarize categories\n[1618.895233631134] Create dummies completed - train\n[1622.315905570984] Create dummies completed - test\n[1628.364058971405] Create sparse merge train completed\n[1630.564956188202] Create sparse merge test completed\nTotal e: 15504096.409612142\nTotal e: 2902910.001301158\nTotal e: 1036519.5830629533\n[1776.074116230011] Train FM completed\n[1786.0805716514587] Predict FM completed\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/_univariate_selection.py:302: RuntimeWarning: invalid value encountered in true_divide\n  corr /= X_norms\n","output_type":"stream"},{"name":"stdout","text":"[1797.7173612117767] Select best completed\n[1797.8618202209473] Garbage collection\n[1854.3474299907684] Finished TFIDF vectorize `name` (1/2)\n[1870.1421220302582] Finished TFIDF vectorize `name` (2/2)\n[2223.330397129059] Finished TFIDF vectorize `item_description` (1/2)\n[2314.8363580703735] Finished TFIDF vectorize `item_description` (2/2)\n[2330.2128829956055] Create sparse merge train completed\n[2336.3542737960815] Create sparse merge test completed\n[2336.766762971878] Finished splitting\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:556: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n  '\"sag\" solver requires many iterations to fit '\n","output_type":"stream"},{"name":"stdout","text":"[2402.273811817169] Finished to train ridge (1)\n[2402.7203180789948] Finished to predict ridge (1)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:556: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n  '\"sag\" solver requires many iterations to fit '\n","output_type":"stream"},{"name":"stdout","text":"[2468.3881673812866] Finished to train ridge (2)\n[2468.8812594413757] Finished to predict ridge (2)\nRMSLE OOF: 0.4542209379440923\n[2469.548060655594] Finished to train MNB (1)\n[2470.7149062156677] Finished to predict MNB (1)\n[2471.402845621109] Finished to train MNB (2)\n[2472.571113586426] Finished to predict MNB (2)\n[2474.8593430519104] Finished garbage collection\n[2474.8830802440643] Finished adding submodels\n[2478.0593264102936] Finished target encoding\n[2481.288740873337] Finished garbage collection\n[2481.8661963939667] Finished dummyizing model 1/5\n[2482.12157535553] Finished dummyizing model 2/5\n[2484.6985449790955] Finished dummyizing model 3/5\n[2488.3235669136047] Finished dummyizing model 4/5\n[2489.9708757400513] Finished dummyizing model 5/5\n[2492.1555709838867] Finished compiling LGB\n[50]\ttraining's rmse: 0.415304\n[100]\ttraining's rmse: 0.408653\n[150]\ttraining's rmse: 0.404548\n[200]\ttraining's rmse: 0.401021\n[250]\ttraining's rmse: 0.397686\n[300]\ttraining's rmse: 0.394836\n[350]\ttraining's rmse: 0.392293\n[400]\ttraining's rmse: 0.389415\n[450]\ttraining's rmse: 0.38659\n[500]\ttraining's rmse: 0.383498\n[550]\ttraining's rmse: 0.380838\n[600]\ttraining's rmse: 0.378227\n[650]\ttraining's rmse: 0.375502\n[700]\ttraining's rmse: 0.373008\n[750]\ttraining's rmse: 0.370568\n[800]\ttraining's rmse: 0.368173\n[850]\ttraining's rmse: 0.36572\n[900]\ttraining's rmse: 0.363204\n[950]\ttraining's rmse: 0.36068\n[1000]\ttraining's rmse: 0.358083\n[1050]\ttraining's rmse: 0.355552\n[1100]\ttraining's rmse: 0.35332\n[1150]\ttraining's rmse: 0.350755\n[1200]\ttraining's rmse: 0.348121\n[1250]\ttraining's rmse: 0.345317\n[1350]\ttraining's rmse: 0.340471\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:661: RuntimeWarning: overflow encountered in expm1\n","output_type":"stream"},{"name":"stdout","text":"[11204.89683175087] Writing submission done\n","output_type":"stream"}]}]}