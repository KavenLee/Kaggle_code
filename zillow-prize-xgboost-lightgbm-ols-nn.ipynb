{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Parameters\nFUDGE_FACTOR = 1.1200 # Multiply forecasts by this\n\nXGB_WEIGHT = 0.6200\nBASELINE_WEIGHT = 0.0100\nOLS_WEIGHT = 0.0620\nNN_WEIGHT = 0.0800\n\nXGB1_WEIGHT = 0.8000 # Weight of first in combination of two XGB models\n\nBASELINE_PRED = 0.0115 # Baseline based on mean of training data, per Oleg\n\nimport numpy as np\nimport pandas as pd\nimport xgboost as xgb\nfrom sklearn.preprocessing import LabelEncoder\nimport lightgbm as lgb\nimport gc\nfrom sklearn.linear_model import LinearRegression\nimport random\nimport datetime as dt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout, BatchNormalization\nfrom keras.layers.advanced_activations import PReLU\nfrom keras.layers.noise import GaussianDropout\nfrom keras.optimizers import Adam\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer as Imputer\n\n\n# Read in raw data\n\nprint('\\nReading data from disk ... ')\nprop = pd.read_csv('../input/zillow-prize-1/properties_2016.csv')\ntrain = pd.read_csv('../input/zillow-prize-1/train_2016_v2.csv')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-09T11:36:57.391197Z","iopub.execute_input":"2021-07-09T11:36:57.391634Z","iopub.status.idle":"2021-07-09T11:37:23.108931Z","shell.execute_reply.started":"2021-07-09T11:36:57.391546Z","shell.execute_reply":"2021-07-09T11:37:23.107723Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}},{"name":"stdout","text":"\nReading data from disk ... \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3170: DtypeWarning: Columns (22,32,34,49,55) have mixed types.Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler, result=result)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## LightGBM","metadata":{}},{"cell_type":"code","source":"# This section is (I think) originally derived from SIDHARTH's script:\n#   https://www.kaggle.com/sidharthkumar/trying-lightgbm\n# which was forked and tuned by Yuqing Xue:\n#   https://www.kaggle.com/yuqingxue/lightgbm-85-97\n# and updated by me (Andy Harless):\n#   https://www.kaggle.com/aharless/lightgbm-with-outliers-remaining\n# and a lot of additional changes have happened since then\n\n# Process data for LightGBM\n\nprint('\\nProcessing data for LightGBM ... ')\nfor c, dtype in zip(prop.columns, prop.dtypes):\n    if dtype == np.float64:\n        prop[c] = prop[c].astype(np.float32)\n        \ndf_train = train.merge(prop, how='left', on='parcelid')\ndf_train.fillna(df_train.median(),inplace=True)\n\nx_train = df_train.drop(['parcelid','logerror','transactiondate','propertyzoningdesc',\n                        'propertycountylandusecode','fireplacecnt','fireplaceflag'],axis=1)\n\ny_train = df_train['logerror'].values\n\nprint(x_train.shape,y_train.shape)\n\ntrain_columns = x_train.columns\n\nfor c in x_train.dtypes[x_train.dtypes == object].index.values:\n    x_train[c] = (x_train[c]==True)\n    \ndel df_train; gc.collect()\n\nx_train=x_train.values.astype(np.float32, copy=False)\nd_train = lgb.Dataset(x_train,label=y_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T11:43:21.501144Z","iopub.execute_input":"2021-07-09T11:43:21.501568Z","iopub.status.idle":"2021-07-09T11:43:37.553882Z","shell.execute_reply.started":"2021-07-09T11:43:21.501537Z","shell.execute_reply":"2021-07-09T11:43:37.552567Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\nProcessing data for LightGBM ... \n(90275, 53) (90275,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Run LightGBM","metadata":{}},{"cell_type":"code","source":"params={}\nparams['max_bin']=10\nparams['learning_rate']=0.0021 # shrinkage_rate\nparams['boosting_type'] ='gbdt'\nparams['objective']='regression'\nparams['metric']='l1'  # or 'mae'\nparams['sub_feature']=0.345 # feature_fraction (small values -> use very different submodels)\nparams['bagging_fraction']=0.85 # sub_row\nparams['bagging_freq'] = 40\nparams['num_leaves'] = 512 # num_leaf\nparams['min_data']=500  # min_data_in_leaf\nparams['min_hessian']=0.05  # min_sum_hessian_in_leaf\nparams['verbose']=0\nparams['feature_fraction_seed']=2\nparams['bagging_seed']=3\n\nnp.random.seed(0)\nrandom.seed(0)\n\nprint('\\nFitting LightGBM model ... ')\nclf = lgb.train(params,d_train,430)\n\ndel d_train; gc.collect()\ndel x_train; gc.collect()\n\nprint('\\nPrepare for LightGBM prediction ...')\nprint('    Read sample file ...')\n\nsample = pd.read_csv('../input/zillow-prize-1/sample_submission.csv')\nprint('    ... ')\n\nsample['parcelid'] = sample['ParcelId']\nprint('    Merge with propoerty data ... ')\n\ndf_test = sample.merge(prop, on='parcelid',how='left')\nprint('    ... ')\n\nx_test=df_test[train_columns]\nprint('    ... ')\n\ndel df_test; gc.collect()\n\nprint('    Preparing x_test ... ')\n\nfor c in x_test.dtypes[x_test.dtypes == object].index.values:\n    x_test[c] = (x_test[c]==True)\n\nprint('    ... ')\n\nx_test = x_test.values.astype(np.float32,copy=False)\n\nprint('\\nStart LightGBM prediction ... ')\n\np_test = clf.predict(x_test)\ndel x_test; gc.collect()\n\nprint('\\nUnadjusted LightGBM predictions: ')\nprint(pd.DataFrame(p_test).head())","metadata":{"execution":{"iopub.status.busy":"2021-07-09T11:57:05.101784Z","iopub.execute_input":"2021-07-09T11:57:05.102226Z","iopub.status.idle":"2021-07-09T12:00:10.799537Z","shell.execute_reply.started":"2021-07-09T11:57:05.102194Z","shell.execute_reply":"2021-07-09T12:00:10.797355Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\nFitting LightGBM model ... \n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011292 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\nPrepare for LightGBM prediction ...\n    Read sample file ...\n    ... \n    Merge with propoerty data ... \n    ... \n    ... \n    Preparing x_test ... \n    ... \n\nStart LightGBM prediction ... \n\nUnadjusted LightGBM predictions: \n          0\n0  0.031132\n1  0.033375\n2  0.010257\n3  0.008651\n4  0.009660\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# XGBoost","metadata":{}},{"cell_type":"code","source":"# This section is (I think) originally derived from Infinite Wing's script:\n#   https://www.kaggle.com/infinitewing/xgboost-without-outliers-lb-0-06463\n# inspired by this thread:\n#   https://www.kaggle.com/c/zillow-prize-1/discussion/33710\n# but the code has gone through a lot of changes since then\n\n\n##### RE-READ PROPERTIES FILE\n##### (I tried keeping a copy, but the program crashed.)\n\nprint( \"\\nRe-reading properties file ...\")\nproperties = pd.read_csv('../input/zillow-prize-1/properties_2016.csv')\n\n\n\n##### PROCESS DATA FOR XGBOOST\n\nprint( \"\\nProcessing data for XGBoost ...\")\nfor c in properties.columns:\n    properties[c]=properties[c].fillna(-1)\n    if properties[c].dtype == 'object':\n        lbl = LabelEncoder()\n        lbl.fit(list(properties[c].values))\n        properties[c] = lbl.transform(list(properties[c].values))\n\ntrain_df = train.merge(properties, how='left', on='parcelid')\nx_train = train_df.drop(['parcelid', 'logerror','transactiondate'], axis=1)\nx_test = properties.drop(['parcelid'], axis=1)\n# shape        \nprint('Shape train: {}\\nShape test: {}'.format(x_train.shape, x_test.shape))\n\n# drop out ouliers\ntrain_df=train_df[ train_df.logerror > -0.4 ]\ntrain_df=train_df[ train_df.logerror < 0.419 ]\nx_train=train_df.drop(['parcelid', 'logerror','transactiondate'], axis=1)\ny_train = train_df[\"logerror\"].values.astype(np.float32)\ny_mean = np.mean(y_train)\n\nprint('After removing outliers:')     \nprint('Shape train: {}\\nShape test: {}'.format(x_train.shape, x_test.shape))","metadata":{"execution":{"iopub.status.busy":"2021-07-09T12:00:49.851372Z","iopub.execute_input":"2021-07-09T12:00:49.851780Z","iopub.status.idle":"2021-07-09T12:01:28.121019Z","shell.execute_reply.started":"2021-07-09T12:00:49.851748Z","shell.execute_reply":"2021-07-09T12:01:28.118726Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"\nRe-reading properties file ...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3170: DtypeWarning: Columns (22,32,34,49,55) have mixed types.Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler, result=result)\n","output_type":"stream"},{"name":"stdout","text":"\nProcessing data for XGBoost ...\nShape train: (90275, 57)\nShape test: (2985217, 57)\nAfter removing outliers:\nShape train: (88528, 57)\nShape test: (2985217, 57)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Run XGBoost","metadata":{}},{"cell_type":"code","source":"print(\"\\nSetting up data for XGBoost ...\")\n# xgboost params\nxgb_params = {\n    'eta': 0.037,\n    'max_depth': 5,\n    'subsample': 0.80,\n    'objective': 'reg:linear',\n    'eval_metric': 'mae',\n    'lambda': 0.8,   \n    'alpha': 0.4, \n    'base_score': y_mean,\n    'silent': 1\n}\n\ndtrain = xgb.DMatrix(x_train, y_train)\ndtest = xgb.DMatrix(x_test)\n\nnum_boost_rounds = 250\nprint(\"num_boost_rounds=\"+str(num_boost_rounds))\n\n# train model\nprint( \"\\nTraining XGBoost ...\")\nmodel = xgb.train(dict(xgb_params, silent=1), dtrain, num_boost_round=num_boost_rounds)\n\nprint( \"\\nPredicting with XGBoost ...\")\nxgb_pred1 = model.predict(dtest)\n\nprint( \"\\nFirst XGBoost predictions:\" )\nprint( pd.DataFrame(xgb_pred1).head() )\n\n\n\n##### RUN XGBOOST AGAIN\n\nprint(\"\\nSetting up data for XGBoost ...\")\n# xgboost params\nxgb_params = {\n    'eta': 0.033,\n    'max_depth': 6,\n    'subsample': 0.80,\n    'objective': 'reg:linear',\n    'eval_metric': 'mae',\n    'base_score': y_mean,\n    'silent': 1\n}\n\nnum_boost_rounds = 150\nprint(\"num_boost_rounds=\"+str(num_boost_rounds))\n\nprint( \"\\nTraining XGBoost again ...\")\nmodel = xgb.train(dict(xgb_params, silent=1), dtrain, num_boost_round=num_boost_rounds)\n\nprint( \"\\nPredicting with XGBoost again ...\")\nxgb_pred2 = model.predict(dtest)\n\nprint( \"\\nSecond XGBoost predictions:\" )\nprint( pd.DataFrame(xgb_pred2).head() )\n\n\n\n##### COMBINE XGBOOST RESULTS\nxgb_pred = XGB1_WEIGHT*xgb_pred1 + (1-XGB1_WEIGHT)*xgb_pred2\n#xgb_pred = xgb_pred1\n\nprint( \"\\nCombined XGBoost predictions:\" )\nprint( pd.DataFrame(xgb_pred).head() )\n\ndel train_df\ndel x_train\ndel x_test\ndel properties\ndel dtest\ndel dtrain\ndel xgb_pred1\ndel xgb_pred2 \ngc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-09T12:03:00.523596Z","iopub.execute_input":"2021-07-09T12:03:00.524098Z","iopub.status.idle":"2021-07-09T12:05:30.064693Z","shell.execute_reply.started":"2021-07-09T12:03:00.524013Z","shell.execute_reply":"2021-07-09T12:05:30.063481Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"\nSetting up data for XGBoost ...\nnum_boost_rounds=250\n\nTraining XGBoost ...\n[12:03:04] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n[12:03:04] WARNING: ../src/learner.cc:573: \nParameters: { \"silent\" } might not be used.\n\n  This may not be accurate due to some parameters are only used in language bindings but\n  passed down to XGBoost core.  Or some parameters are not used but slip through this\n  verification. Please open an issue if you find above cases.\n\n\n\nPredicting with XGBoost ...\n\nFirst XGBoost predictions:\n          0\n0 -0.030616\n1 -0.028188\n2  0.026397\n3  0.063728\n4  0.004398\n\nSetting up data for XGBoost ...\nnum_boost_rounds=150\n\nTraining XGBoost again ...\n[12:04:28] WARNING: ../src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n[12:04:28] WARNING: ../src/learner.cc:573: \nParameters: { \"silent\" } might not be used.\n\n  This may not be accurate due to some parameters are only used in language bindings but\n  passed down to XGBoost core.  Or some parameters are not used but slip through this\n  verification. Please open an issue if you find above cases.\n\n\n\nPredicting with XGBoost again ...\n\nSecond XGBoost predictions:\n          0\n0 -0.091150\n1 -0.034722\n2  0.015816\n3  0.075518\n4  0.029908\n\nCombined XGBoost predictions:\n          0\n0 -0.042723\n1 -0.029495\n2  0.024281\n3  0.066086\n4  0.009500\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"548"},"metadata":{}}]},{"cell_type":"markdown","source":"# Neural Network","metadata":{}},{"cell_type":"code","source":"# Neural network copied from this script:\n#   https://www.kaggle.com/aharless/keras-neural-network-lb-06492 (version 20)\n# which was built on the skeleton in this notebook:\n#   https://www.kaggle.com/prasunmishra/ann-using-keras\n\n\n# Read in data for neural network\nprint( \"\\n\\nProcessing data for Neural Network ...\")\nprint('\\nLoading train, prop and sample data...')\ntrain = pd.read_csv(\"../input/zillow-prize-1/train_2016_v2.csv\", parse_dates=[\"transactiondate\"])\nprop = pd.read_csv('../input/zillow-prize-1/properties_2016.csv')\nsample = pd.read_csv('../input/zillow-prize-1/sample_submission.csv')\n \nprint('Fitting Label Encoder on properties...')\nfor c in prop.columns:\n    prop[c]=prop[c].fillna(-1)\n    if prop[c].dtype == 'object':\n        lbl = LabelEncoder()\n        lbl.fit(list(prop[c].values))\n        prop[c] = lbl.transform(list(prop[c].values))\n        \nprint('Creating training set...')\ndf_train = train.merge(prop, how='left', on='parcelid')\n\ndf_train[\"transactiondate\"] = pd.to_datetime(df_train[\"transactiondate\"])\ndf_train[\"transactiondate_year\"] = df_train[\"transactiondate\"].dt.year\ndf_train[\"transactiondate_month\"] = df_train[\"transactiondate\"].dt.month\ndf_train['transactiondate_quarter'] = df_train['transactiondate'].dt.quarter\ndf_train[\"transactiondate\"] = df_train[\"transactiondate\"].dt.day\n\nprint('Filling NA/NaN values...' )\ndf_train.fillna(-1.0)\n\nprint('Creating x_train and y_train from df_train...' )\nx_train = df_train.drop(['parcelid', 'logerror', 'transactiondate', 'propertyzoningdesc', 'propertycountylandusecode','fireplacecnt', 'fireplaceflag'], axis=1)\ny_train = df_train[\"logerror\"]\n\ny_mean = np.mean(y_train)\nprint(x_train.shape, y_train.shape)\ntrain_columns = x_train.columns\n\nfor c in x_train.dtypes[x_train.dtypes == object].index.values:\n    x_train[c] = (x_train[c] == True)\n\nprint('Creating df_test...')\nsample['parcelid'] = sample['ParcelId']\n\nprint(\"Merging Sample with property data...\")\ndf_test = sample.merge(prop, on='parcelid', how='left')\n\ndf_test[\"transactiondate\"] = pd.to_datetime('2016-11-15')  # placeholder value for preliminary version\ndf_test[\"transactiondate_year\"] = df_test[\"transactiondate\"].dt.year\ndf_test[\"transactiondate_month\"] = df_test[\"transactiondate\"].dt.month\ndf_test['transactiondate_quarter'] = df_test['transactiondate'].dt.quarter\ndf_test[\"transactiondate\"] = df_test[\"transactiondate\"].dt.day     \nx_test = df_test[train_columns]\n\nprint('Shape of x_test:', x_test.shape)\nprint(\"Preparing x_test...\")\nfor c in x_test.dtypes[x_test.dtypes == object].index.values:\n    x_test[c] = (x_test[c] == True)\n  \n\n## Preprocessing\nprint(\"\\nPreprocessing neural network data...\")\nimputer= Imputer()\nimputer.fit(x_train.iloc[:, :])\nx_train = imputer.transform(x_train.iloc[:, :])\nimputer.fit(x_test.iloc[:, :])\nx_test = imputer.transform(x_test.iloc[:, :])\n\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)\n\nlen_x=int(x_train.shape[1])\nprint(\"len_x is:\",len_x)\n\n\n# Neural Network\nprint(\"\\nSetting up neural network model...\")\nnn = Sequential()\nnn.add(Dense(units = 400 , kernel_initializer = 'normal', input_dim = len_x))\nnn.add(PReLU())\nnn.add(Dropout(.4))\nnn.add(Dense(units = 160 , kernel_initializer = 'normal'))\nnn.add(PReLU())\nnn.add(BatchNormalization())\nnn.add(Dropout(.6))\nnn.add(Dense(units = 64 , kernel_initializer = 'normal'))\nnn.add(PReLU())\nnn.add(BatchNormalization())\nnn.add(Dropout(.5))\nnn.add(Dense(units = 26, kernel_initializer = 'normal'))\nnn.add(PReLU())\nnn.add(BatchNormalization())\nnn.add(Dropout(.6))\nnn.add(Dense(1, kernel_initializer='normal'))\nnn.compile(loss='mae', optimizer=Adam(lr=4e-3, decay=1e-4))\n\nprint(\"\\nFitting neural network model...\")\nnn.fit(np.array(x_train), np.array(y_train), batch_size = 32, epochs = 70, verbose=2)\n\nprint(\"\\nPredicting with neural network model...\")\n#print(\"x_test.shape:\",x_test.shape)\ny_pred_ann = nn.predict(x_test)\n\nprint( \"\\nPreparing results for write...\" )\nnn_pred = y_pred_ann.flatten()\nprint( \"Type of nn_pred is \", type(nn_pred) )\nprint( \"Shape of nn_pred is \", nn_pred.shape )\n\nprint( \"\\nNeural Network predictions:\" )\nprint( pd.DataFrame(nn_pred).head() )\n\n\n# Cleanup\ndel train\ndel prop\ndel sample\ndel x_train\ndel x_test\ndel df_train\ndel df_test\ndel y_pred_ann\ngc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-09T12:05:53.863521Z","iopub.execute_input":"2021-07-09T12:05:53.863876Z","iopub.status.idle":"2021-07-09T12:25:07.434056Z","shell.execute_reply.started":"2021-07-09T12:05:53.863846Z","shell.execute_reply":"2021-07-09T12:25:07.433001Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"\n\nProcessing data for Neural Network ...\n\nLoading train, prop and sample data...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3170: DtypeWarning: Columns (22,32,34,49,55) have mixed types.Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler, result=result)\n","output_type":"stream"},{"name":"stdout","text":"Fitting Label Encoder on properties...\nCreating training set...\nFilling NA/NaN values...\nCreating x_train and y_train from df_train...\n(90275, 56) (90275,)\nCreating df_test...\nMerging Sample with property data...\nShape of x_test: (2985217, 56)\nPreparing x_test...\n\nPreprocessing neural network data...\nlen_x is: 56\n\nSetting up neural network model...\n\nFitting neural network model...\nEpoch 1/70\n2822/2822 - 16s - loss: 0.0708\nEpoch 2/70\n2822/2822 - 14s - loss: 0.0682\nEpoch 3/70\n2822/2822 - 14s - loss: 0.0682\nEpoch 4/70\n2822/2822 - 14s - loss: 0.0681\nEpoch 5/70\n2822/2822 - 14s - loss: 0.0680\nEpoch 6/70\n2822/2822 - 14s - loss: 0.0680\nEpoch 7/70\n2822/2822 - 14s - loss: 0.0679\nEpoch 8/70\n2822/2822 - 13s - loss: 0.0679\nEpoch 9/70\n2822/2822 - 14s - loss: 0.0678\nEpoch 10/70\n2822/2822 - 13s - loss: 0.0678\nEpoch 11/70\n2822/2822 - 15s - loss: 0.0678\nEpoch 12/70\n2822/2822 - 14s - loss: 0.0677\nEpoch 13/70\n2822/2822 - 14s - loss: 0.0677\nEpoch 14/70\n2822/2822 - 14s - loss: 0.0677\nEpoch 15/70\n2822/2822 - 14s - loss: 0.0676\nEpoch 16/70\n2822/2822 - 14s - loss: 0.0676\nEpoch 17/70\n2822/2822 - 14s - loss: 0.0676\nEpoch 18/70\n2822/2822 - 14s - loss: 0.0676\nEpoch 19/70\n2822/2822 - 14s - loss: 0.0676\nEpoch 20/70\n2822/2822 - 14s - loss: 0.0675\nEpoch 21/70\n2822/2822 - 14s - loss: 0.0676\nEpoch 22/70\n2822/2822 - 14s - loss: 0.0675\nEpoch 23/70\n2822/2822 - 14s - loss: 0.0675\nEpoch 24/70\n2822/2822 - 14s - loss: 0.0675\nEpoch 25/70\n2822/2822 - 14s - loss: 0.0675\nEpoch 26/70\n2822/2822 - 14s - loss: 0.0675\nEpoch 27/70\n2822/2822 - 14s - loss: 0.0674\nEpoch 28/70\n2822/2822 - 14s - loss: 0.0675\nEpoch 29/70\n2822/2822 - 14s - loss: 0.0674\nEpoch 30/70\n2822/2822 - 14s - loss: 0.0675\nEpoch 31/70\n2822/2822 - 14s - loss: 0.0674\nEpoch 32/70\n2822/2822 - 15s - loss: 0.0674\nEpoch 33/70\n2822/2822 - 14s - loss: 0.0674\nEpoch 34/70\n2822/2822 - 14s - loss: 0.0674\nEpoch 35/70\n2822/2822 - 14s - loss: 0.0674\nEpoch 36/70\n2822/2822 - 14s - loss: 0.0674\nEpoch 37/70\n2822/2822 - 15s - loss: 0.0674\nEpoch 38/70\n2822/2822 - 14s - loss: 0.0674\nEpoch 39/70\n2822/2822 - 14s - loss: 0.0674\nEpoch 40/70\n2822/2822 - 14s - loss: 0.0674\nEpoch 41/70\n2822/2822 - 14s - loss: 0.0674\nEpoch 42/70\n2822/2822 - 14s - loss: 0.0674\nEpoch 43/70\n2822/2822 - 14s - loss: 0.0673\nEpoch 44/70\n2822/2822 - 14s - loss: 0.0673\nEpoch 45/70\n2822/2822 - 14s - loss: 0.0673\nEpoch 46/70\n2822/2822 - 14s - loss: 0.0674\nEpoch 47/70\n2822/2822 - 14s - loss: 0.0673\nEpoch 48/70\n2822/2822 - 14s - loss: 0.0673\nEpoch 49/70\n2822/2822 - 14s - loss: 0.0673\nEpoch 50/70\n2822/2822 - 14s - loss: 0.0673\nEpoch 51/70\n2822/2822 - 14s - loss: 0.0673\nEpoch 52/70\n2822/2822 - 15s - loss: 0.0673\nEpoch 53/70\n2822/2822 - 14s - loss: 0.0673\nEpoch 54/70\n2822/2822 - 15s - loss: 0.0673\nEpoch 55/70\n2822/2822 - 14s - loss: 0.0673\nEpoch 56/70\n2822/2822 - 14s - loss: 0.0673\nEpoch 57/70\n2822/2822 - 14s - loss: 0.0673\nEpoch 58/70\n2822/2822 - 14s - loss: 0.0673\nEpoch 59/70\n2822/2822 - 14s - loss: 0.0673\nEpoch 60/70\n2822/2822 - 14s - loss: 0.0672\nEpoch 61/70\n2822/2822 - 14s - loss: 0.0673\nEpoch 62/70\n2822/2822 - 14s - loss: 0.0672\nEpoch 63/70\n2822/2822 - 14s - loss: 0.0672\nEpoch 64/70\n2822/2822 - 13s - loss: 0.0672\nEpoch 65/70\n2822/2822 - 14s - loss: 0.0672\nEpoch 66/70\n2822/2822 - 14s - loss: 0.0673\nEpoch 67/70\n2822/2822 - 13s - loss: 0.0672\nEpoch 68/70\n2822/2822 - 13s - loss: 0.0672\nEpoch 69/70\n2822/2822 - 14s - loss: 0.0672\nEpoch 70/70\n2822/2822 - 14s - loss: 0.0672\n\nPredicting with neural network model...\n\nPreparing results for write...\nType of nn_pred is  <class 'numpy.ndarray'>\nShape of nn_pred is  (2985217,)\n\nNeural Network predictions:\n          0\n0 -0.010197\n1 -0.013039\n2  0.804989\n3  0.101534\n4  0.108164\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"1704"},"metadata":{}}]},{"cell_type":"markdown","source":"# OLS","metadata":{}},{"cell_type":"code","source":"# This section is derived from the1owl's notebook:\n#    https://www.kaggle.com/the1owl/primer-for-the-zillow-pred-approach\n# which I (Andy Harless) updated and made into a script:\n#    https://www.kaggle.com/aharless/updated-script-version-of-the1owl-s-basic-ols\n\nnp.random.seed(17)\nrandom.seed(17)\n\nprint( \"\\n\\nProcessing data for OLS ...\")\n\ntrain = pd.read_csv(\"../input/zillow-prize-1/train_2016_v2.csv\", parse_dates=[\"transactiondate\"])\nproperties = pd.read_csv(\"../input/zillow-prize-1/properties_2016.csv\")\nsubmission = pd.read_csv(\"../input/zillow-prize-1/sample_submission.csv\")\nprint(len(train),len(properties),len(submission))\n\ndef get_features(df):\n    df[\"transactiondate\"] = pd.to_datetime(df[\"transactiondate\"])\n    df[\"transactiondate_year\"] = df[\"transactiondate\"].dt.year\n    df[\"transactiondate_month\"] = df[\"transactiondate\"].dt.month\n    df['transactiondate'] = df['transactiondate'].dt.quarter\n    df = df.fillna(-1.0)\n    return df\n\ndef MAE(y, ypred):\n    #logerror=log(Zestimate)log(SalePrice)\n    return np.sum([abs(y[i]-ypred[i]) for i in range(len(y))]) / len(y)\n\ntrain = pd.merge(train, properties, how='left', on='parcelid')\ny = train['logerror'].values\ntest = pd.merge(submission, properties, how='left', left_on='ParcelId', right_on='parcelid')\nproperties = [] #memory\n\nexc = [train.columns[c] for c in range(len(train.columns)) if train.dtypes[c] == 'O'] + ['logerror','parcelid']\ncol = [c for c in train.columns if c not in exc]\n\ntrain = get_features(train[col])\ntest['transactiondate'] = '2016-01-01' #should use the most common training date\ntest = get_features(test[col])\n\n\nprint(\"\\nFitting OLS...\")\nreg = LinearRegression(n_jobs=-1)\nreg.fit(train, y); print('fit...')\nprint(MAE(y, reg.predict(train)))\ntrain = [];  y = [] #memory\n\ntest_dates = ['2016-10-01','2016-11-01','2016-12-01','2017-10-01','2017-11-01','2017-12-01']\ntest_columns = ['201610','201611','201612','201710','201711','201712']","metadata":{"execution":{"iopub.status.busy":"2021-07-09T12:25:14.738157Z","iopub.execute_input":"2021-07-09T12:25:14.738540Z","iopub.status.idle":"2021-07-09T12:25:44.230702Z","shell.execute_reply.started":"2021-07-09T12:25:14.738509Z","shell.execute_reply":"2021-07-09T12:25:44.229414Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"\n\nProcessing data for OLS ...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3170: DtypeWarning: Columns (22,32,34,49,55) have mixed types.Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler, result=result)\n","output_type":"stream"},{"name":"stdout","text":"90275 2985217 2985217\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","output_type":"stream"},{"name":"stdout","text":"\nFitting OLS...\nfit...\n0.06837008658086659\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Combine and Save","metadata":{}},{"cell_type":"code","source":"# COMBINE PREDICTIONS\n\nprint( \"\\nCombining XGBoost, LightGBM, NN, and baseline predicitons ...\" )\nlgb_weight = 1 - XGB_WEIGHT - BASELINE_WEIGHT - NN_WEIGHT - OLS_WEIGHT \nlgb_weight0 = lgb_weight / (1 - OLS_WEIGHT)\nxgb_weight0 = XGB_WEIGHT / (1 - OLS_WEIGHT)\nbaseline_weight0 =  BASELINE_WEIGHT / (1 - OLS_WEIGHT)\nnn_weight0 = NN_WEIGHT / (1 - OLS_WEIGHT)\npred0 = 0\npred0 += xgb_weight0*xgb_pred\npred0 += baseline_weight0*BASELINE_PRED\npred0 += lgb_weight0*p_test\npred0 += nn_weight0*nn_pred\n\nprint( \"\\nCombined XGB/LGB/NN/baseline predictions:\" )\nprint( pd.DataFrame(pred0).head() )\n\nprint( \"\\nPredicting with OLS and combining with XGB/LGB/NN/baseline predicitons: ...\" )\nfor i in range(len(test_dates)):\n    test['transactiondate'] = test_dates[i]\n    pred = FUDGE_FACTOR * ( OLS_WEIGHT*reg.predict(get_features(test)) + (1-OLS_WEIGHT)*pred0 )\n    submission[test_columns[i]] = [float(format(x, '.4f')) for x in pred]\n    print('predict...', i)\n\nprint( \"\\nCombined XGB/LGB/NN/baseline/OLS predictions:\" )\nprint( submission.head() )\n\n\n\n# WRITE THE RESULTS\n\nfrom datetime import datetime\n\nprint( \"\\nWriting results to disk ...\" )\nsubmission.to_csv('sub{}.csv'.format(datetime.now().strftime('%Y%m%d_%H%M%S')), index=False)\n\nprint( \"\\nFinished ...\")","metadata":{"execution":{"iopub.status.busy":"2021-07-09T12:26:21.819759Z","iopub.execute_input":"2021-07-09T12:26:21.820166Z","iopub.status.idle":"2021-07-09T12:27:30.723652Z","shell.execute_reply.started":"2021-07-09T12:26:21.820131Z","shell.execute_reply":"2021-07-09T12:27:30.721474Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"\nCombining XGBoost, LightGBM, NN, and baseline predicitons ...\n\nCombined XGB/LGB/NN/baseline predictions:\n          0\n0 -0.021419\n1 -0.012373\n2  0.087321\n3  0.054566\n4  0.017975\n\nPredicting with OLS and combining with XGB/LGB/NN/baseline predicitons: ...\npredict... 0\npredict... 1\npredict... 2\npredict... 3\npredict... 4\npredict... 5\n\nCombined XGB/LGB/NN/baseline/OLS predictions:\n   ParcelId  201610  201611  201612  201710  201711  201712\n0  10754147 -0.0248 -0.0248 -0.0248 -0.0248 -0.0248 -0.0248\n1  10759547 -0.0157 -0.0157 -0.0157 -0.0157 -0.0157 -0.0157\n2  10843547  0.1368  0.1368  0.1368  0.1368  0.1368  0.1368\n3  10859147  0.0600  0.0600  0.0600  0.0600  0.0600  0.0600\n4  10879947  0.0210  0.0210  0.0210  0.0210  0.0210  0.0210\n\nWriting results to disk ...\n\nFinished ...\n","output_type":"stream"}]}]}